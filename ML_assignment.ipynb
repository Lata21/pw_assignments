{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSXHSlXSrVeEJvRXaJpmS2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lata21/pw_assignments/blob/main/ML_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "me-iYmIhlmHO",
        "outputId": "3372cda5-6853-4389-9a36-44cd0db1b95f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI :- Ai stands for artifical intelligence . AI is a smart application they can perform its own task without any explicit of humna interactiiom\\nEX:- self driving cars , robots , Alexa\\n\\nML:- ML stands for the machine learning it provides statistics tools to analyze , visualize , to make model predictive , Forecasting the model.\\nEX:-Netflix having the recommendation system.\\n\\nDL :- Deep Learning is to mimic the human brain , its a multilayered neural network.\\nEx:- image recognition ,object detection.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#1.\n",
        "'''AI :- Ai stands for artifical intelligence . AI is a smart application they can perform its own task without any explicit of humna interactiiom\n",
        "EX:- self driving cars , robots , Alexa\n",
        "\n",
        "ML:- ML stands for the machine learning it provides statistics tools to analyze , visualize , to make model predictive , Forecasting the model.\n",
        "EX:-Netflix having the recommendation system.\n",
        "\n",
        "DL :- Deep Learning is to mimic the human brain , its a multilayered neural network.\n",
        "Ex:- image recognition ,object detection.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.\n",
        "''' Supervised Learning:- In Supervised learning we know the input and output both and according to that we have to train the model. It classifies in two types basically\n",
        "1. Classification :- The output feature is Categorical\n",
        "2. Regression:- The output feature is Continous.\n",
        "\n",
        "list of the examples:-\n",
        "Credit Scoring.\n",
        "Voice Recognition\n",
        "Regression.\n",
        "Naive Bayes.\n",
        "Classification.\n",
        "Neutral Networks.\n",
        "Random Forest.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "8VrxTo7hnRNe",
        "outputId": "ad97c2a9-4f9f-40fa-db79-59e8525633ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Supervised Learning:- In Supervised learning we know the input and output both and according to that we have to train the model. It classifies in two types basically\\n1. Classification :- The output feature is Categorical\\n2. Regression:- The output feature is Continous.\\n\\nlist of the examples:-\\nCredit Scoring. \\nVoice Recognition\\nRegression. \\nNaive Bayes.\\nClassification.\\nNeutral Networks.\\nRandom Forest.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.\n",
        "'''Unsupervised Learning:-\n",
        "In this Unsupervised Learning we do not having of knowing the output we make clusters to understand the data.\n",
        "Clusters means the grouping.\n",
        "We trying to group them into segemnts.\n",
        "\n",
        "List of Unsupervised Learning:-\n",
        "K-means clustering.\n",
        "KNN (k-nearest neighbors)\n",
        "Hierarchal clustering.\n",
        "Anomaly detection.\n",
        "Neural Networks.\n",
        "Principle Component Analysis.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "jrQ9NFs3orkc",
        "outputId": "91b766ce-61b2-458d-df03-4727f9c6eb15"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unsupervised Learning:-\\nIn this Unsupervised Learning we do not having of knowing the output we make clusters to understand the data.\\nClusters means the grouping.\\nWe trying to group them into segemnts.\\n\\nList of Unsupervised Learning:-\\nK-means clustering.\\nKNN (k-nearest neighbors)\\nHierarchal clustering.\\nAnomaly detection.\\nNeural Networks.\\nPrinciple Component Analysis.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.\n",
        "''' AI is the overarching field focused on creating intelligent systems, ML is a subset of AI that involves training models to learn from data, DL is a subset of ML that uses deep neural networks for complex tasks, and DS is a multidisciplinary field that leverages various techniques to extract insights from data. These fields often overlap, and advancements in one can benefit the others.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ISuYRTRepoi9",
        "outputId": "37210e61-a6fa-449c-e9a9-c9957f0342e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' AI is the overarching field focused on creating intelligent systems, ML is a subset of AI that involves training models to learn from data, DL is a subset of ML that uses deep neural networks for complex tasks, and DS is a multidisciplinary field that leverages various techniques to extract insights from data. These fields often overlap, and advancements in one can benefit the others.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5.\n",
        "'''the main differences between these three types of learning are the presence or absence of labeled data and the objectives of the learning process. Supervised learning focuses on prediction with labeled data, unsupervised learning focuses on discovering hidden patterns without labels, and semi-supervised learning combines elements of both to leverage labeled data to improve the learning process with unlabeled data. The choice of which paradigm to use depends on the specific problem and the availability of labeled data.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lfwj4ffMp1aX",
        "outputId": "dec03370-c304-4306-94f0-11695f776f9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the main differences between these three types of learning are the presence or absence of labeled data and the objectives of the learning process. Supervised learning focuses on prediction with labeled data, unsupervised learning focuses on discovering hidden patterns without labels, and semi-supervised learning combines elements of both to leverage labeled data to improve the learning process with unlabeled data. The choice of which paradigm to use depends on the specific problem and the availability of labeled data.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6.\n",
        "'''In machine learning, the terms \"training set,\" \"test set,\" and \"validation set\" are used to split a dataset into different subsets for different purposes. Each subset serves a specific role in the machine learning workflow, and their proper use is essential for building and evaluating models effectively. Here's an explanation of each term and their importance:\n",
        "\n",
        "1. **Training Set**:\n",
        "   - The training set is a subset of the dataset that is used to train the machine learning model. It consists of a large portion of the available data.\n",
        "   - Importance: The primary purpose of the training set is to teach the model to learn patterns, relationships, and features in the data. The model's parameters or weights are adjusted during training to minimize the difference between its predictions and the actual target values in this set. A well-trained model should be able to generalize from the training data to make predictions on new, unseen data.\n",
        "\n",
        "2. **Test Set**:\n",
        "   - The test set is another subset of the dataset that is kept separate from the training set. It is not used during the model training phase.\n",
        "   - Importance: The test set is used to evaluate the model's performance and assess how well it generalizes to unseen data. By making predictions on the test set and comparing them to the actual target values, you can estimate the model's accuracy and identify potential issues like overfitting (where the model fits the training data too closely but performs poorly on new data).\n",
        "\n",
        "3. **Validation Set**:\n",
        "   - The validation set, sometimes called a development or holdout set, is a subset of the data that is used during the model development and hyperparameter tuning phase.\n",
        "   - Importance: The validation set helps in selecting the best-performing model and tuning hyperparameters like learning rates, regularization strength, or model architecture. By assessing model performance on the validation set, you can make informed decisions about adjustments needed to improve the model's generalization ability before evaluating it on the test set.\n",
        "\n",
        "Here's a typical workflow involving these splits:\n",
        "1. **Training Phase**: You train your machine learning model using the training set. The model learns from this data and adjusts its parameters to make accurate predictions.\n",
        "\n",
        "2. **Validation Phase**: You assess the model's performance using the validation set, tweaking hyperparameters or adjusting the model as needed to improve its performance on the validation data.\n",
        "\n",
        "3. **Testing Phase**: Once you're satisfied with the model's performance on the validation set and have finalized your model, you use the test set to evaluate its performance on completely unseen data. This provides a reliable estimate of how the model will perform in real-world scenarios.\n",
        "\n",
        "The separation of data into training, validation, and test sets helps ensure that your machine learning model generalizes well and provides reliable predictions on new, unseen data, which is a critical aspect of building robust and effective models.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "v2dghZnNqD91",
        "outputId": "2dc894c8-d5a4-417a-ff60-a198a8711dbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In machine learning, the terms \"training set,\" \"test set,\" and \"validation set\" are used to split a dataset into different subsets for different purposes. Each subset serves a specific role in the machine learning workflow, and their proper use is essential for building and evaluating models effectively. Here\\'s an explanation of each term and their importance:\\n\\n1. **Training Set**:\\n   - The training set is a subset of the dataset that is used to train the machine learning model. It consists of a large portion of the available data.\\n   - Importance: The primary purpose of the training set is to teach the model to learn patterns, relationships, and features in the data. The model\\'s parameters or weights are adjusted during training to minimize the difference between its predictions and the actual target values in this set. A well-trained model should be able to generalize from the training data to make predictions on new, unseen data.\\n\\n2. **Test Set**:\\n   - The test set is another subset of the dataset that is kept separate from the training set. It is not used during the model training phase.\\n   - Importance: The test set is used to evaluate the model\\'s performance and assess how well it generalizes to unseen data. By making predictions on the test set and comparing them to the actual target values, you can estimate the model\\'s accuracy and identify potential issues like overfitting (where the model fits the training data too closely but performs poorly on new data).\\n\\n3. **Validation Set**:\\n   - The validation set, sometimes called a development or holdout set, is a subset of the data that is used during the model development and hyperparameter tuning phase.\\n   - Importance: The validation set helps in selecting the best-performing model and tuning hyperparameters like learning rates, regularization strength, or model architecture. By assessing model performance on the validation set, you can make informed decisions about adjustments needed to improve the model\\'s generalization ability before evaluating it on the test set.\\n\\nHere\\'s a typical workflow involving these splits:\\n1. **Training Phase**: You train your machine learning model using the training set. The model learns from this data and adjusts its parameters to make accurate predictions.\\n\\n2. **Validation Phase**: You assess the model\\'s performance using the validation set, tweaking hyperparameters or adjusting the model as needed to improve its performance on the validation data.\\n\\n3. **Testing Phase**: Once you\\'re satisfied with the model\\'s performance on the validation set and have finalized your model, you use the test set to evaluate its performance on completely unseen data. This provides a reliable estimate of how the model will perform in real-world scenarios.\\n\\nThe separation of data into training, validation, and test sets helps ensure that your machine learning model generalizes well and provides reliable predictions on new, unseen data, which is a critical aspect of building robust and effective models.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7.\n",
        "'''the key idea is to identify data points or patterns that deviate significantly from what is considered normal in the data. Unsupervised learning allows you to do this without the need for labeled anomalies, making it valuable in scenarios where labeled data is scarce or unavailable. However, it's essential to fine-tune the parameters and thresholds to achieve the desired balance between false positives and false negatives in anomaly detection.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "JDKttL0fqOjN",
        "outputId": "340918c4-e208-4f33-9cc8-850da962c895"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the key idea is to identify data points or patterns that deviate significantly from what is considered normal in the data. Unsupervised learning allows you to do this without the need for labeled anomalies, making it valuable in scenarios where labeled data is scarce or unavailable. However, it's essential to fine-tune the parameters and thresholds to achieve the desired balance between false positives and false negatives in anomaly detection.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8.\n",
        "'''Certainly, here are some commonly used supervised and unsupervised learning algorithms:\n",
        "\n",
        "**Supervised Learning Algorithms:**\n",
        "\n",
        "1. **Linear Regression**: Used for regression tasks to predict a continuous target variable.\n",
        "\n",
        "2. **Logistic Regression**: Used for binary and multi-class classification problems.\n",
        "\n",
        "3. **Decision Trees**: Tree-like structures used for both classification and regression tasks.\n",
        "\n",
        "4. **Random Forest**: An ensemble method based on decision trees for improved accuracy and robustness.\n",
        "\n",
        "5. **Support Vector Machines (SVM)**: Effective for binary classification, separating data points with a hyperplane.\n",
        "\n",
        "6. **K-Nearest Neighbors (KNN)**: Classification algorithm that assigns a class based on the majority class among its k-nearest neighbors.\n",
        "\n",
        "7. **Naive Bayes**: A probabilistic classifier based on Bayes' theorem, often used for text classification.\n",
        "\n",
        "8. **Neural Networks (Deep Learning)**: Multi-layer artificial neural networks used for various tasks, including image and speech recognition.\n",
        "\n",
        "9. **Gradient Boosting Algorithms**: Such as Gradient Boosting Machines (GBM), XGBoost, and LightGBM, for boosting ensemble learning.\n",
        "\n",
        "10. **Linear Discriminant Analysis (LDA)**: Used for dimensionality reduction and classification tasks.\n",
        "\n",
        "**Unsupervised Learning Algorithms:**\n",
        "\n",
        "1. **K-Means Clustering**: Divides data into k clusters based on similarity.\n",
        "\n",
        "2. **Hierarchical Clustering**: Builds a hierarchy of clusters, which can be visualized as a tree-like structure.\n",
        "\n",
        "3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: Clusters data points based on density in high-dimensional spaces.\n",
        "\n",
        "4. **PCA (Principal Component Analysis)**: Reduces the dimensionality of data while preserving variance.\n",
        "\n",
        "5. **Autoencoders**: Neural network-based technique for dimensionality reduction and feature learning.\n",
        "\n",
        "6. **Isolation Forest**: Anomaly detection algorithm based on decision trees.\n",
        "\n",
        "7. **Gaussian Mixture Models (GMM)**: Models data as a mixture of multiple Gaussian distributions.\n",
        "\n",
        "8. **Self-Organizing Maps (SOM)**: Neural network-based technique for dimensionality reduction and clustering.\n",
        "\n",
        "9. **t-SNE (t-Distributed Stochastic Neighbor Embedding)**: Dimensionality reduction technique often used for visualization.\n",
        "\n",
        "10. **UMAP (Uniform Manifold Approximation and Projection)**: Non-linear dimensionality reduction and clustering technique.\n",
        "\n",
        "These are just some of the most commonly used algorithms in both supervised and unsupervised learning. The choice of algorithm depends on the specific task, the nature of the data, and the goals of the machine learning project. It's often a good practice to experiment with multiple algorithms to determine which one works best for a given problem.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "4-uAeg72qaMt",
        "outputId": "7b664c94-5162-4fa4-b575-432a5aa0f6ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Certainly, here are some commonly used supervised and unsupervised learning algorithms:\\n\\n**Supervised Learning Algorithms:**\\n\\n1. **Linear Regression**: Used for regression tasks to predict a continuous target variable.\\n\\n2. **Logistic Regression**: Used for binary and multi-class classification problems.\\n\\n3. **Decision Trees**: Tree-like structures used for both classification and regression tasks.\\n\\n4. **Random Forest**: An ensemble method based on decision trees for improved accuracy and robustness.\\n\\n5. **Support Vector Machines (SVM)**: Effective for binary classification, separating data points with a hyperplane.\\n\\n6. **K-Nearest Neighbors (KNN)**: Classification algorithm that assigns a class based on the majority class among its k-nearest neighbors.\\n\\n7. **Naive Bayes**: A probabilistic classifier based on Bayes' theorem, often used for text classification.\\n\\n8. **Neural Networks (Deep Learning)**: Multi-layer artificial neural networks used for various tasks, including image and speech recognition.\\n\\n9. **Gradient Boosting Algorithms**: Such as Gradient Boosting Machines (GBM), XGBoost, and LightGBM, for boosting ensemble learning.\\n\\n10. **Linear Discriminant Analysis (LDA)**: Used for dimensionality reduction and classification tasks.\\n\\n**Unsupervised Learning Algorithms:**\\n\\n1. **K-Means Clustering**: Divides data into k clusters based on similarity.\\n\\n2. **Hierarchical Clustering**: Builds a hierarchy of clusters, which can be visualized as a tree-like structure.\\n\\n3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: Clusters data points based on density in high-dimensional spaces.\\n\\n4. **PCA (Principal Component Analysis)**: Reduces the dimensionality of data while preserving variance.\\n\\n5. **Autoencoders**: Neural network-based technique for dimensionality reduction and feature learning.\\n\\n6. **Isolation Forest**: Anomaly detection algorithm based on decision trees.\\n\\n7. **Gaussian Mixture Models (GMM)**: Models data as a mixture of multiple Gaussian distributions.\\n\\n8. **Self-Organizing Maps (SOM)**: Neural network-based technique for dimensionality reduction and clustering.\\n\\n9. **t-SNE (t-Distributed Stochastic Neighbor Embedding)**: Dimensionality reduction technique often used for visualization.\\n\\n10. **UMAP (Uniform Manifold Approximation and Projection)**: Non-linear dimensionality reduction and clustering technique.\\n\\nThese are just some of the most commonly used algorithms in both supervised and unsupervised learning. The choice of algorithm depends on the specific task, the nature of the data, and the goals of the machine learning project. It's often a good practice to experiment with multiple algorithms to determine which one works best for a given problem.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWrsPUhOqlES"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}